![image](https://github.com/Lexie88rus/Activation-functions-examples-pytorch/raw/master/assets/blur-blurry-close-up-167259.jpg)

# Custom Activation Functions Examples for PyTorch
Repository containing the article with examples of custom activation functions for Pytorch and scripts used in the article.
See the [article on Medium](https://towardsdatascience.com/extending-pytorch-with-custom-activation-functions-2d8b065ef2fa) and a [kernel on Kaggle](https://www.kaggle.com/aleksandradeis/extending-pytorch-with-custom-activation-functions).

## Introduction
Today deep learning is going viral and is applied to a variety of machine learning problems such as image recognition, speech recognition, machine translation, and others. There is a wide range of highly customizable neural network architectures, which can suit almost any problem when given enough data. Each neural network should be elaborated to suit the given problem well enough. You have to fine tune the hyperparameters of the network (the learning rate, dropout coefficients, weight decay, and many others) as well as the number of hidden layers, and the number of units in each layer. __Choosing the right activation function for each layer is also crucial and may have a significant impact on metric scores and the training speed of the model.__

## References
* My original [article on Medium](https://towardsdatascience.com/extending-pytorch-with-custom-activation-functions-2d8b065ef2fa)
* My related [kernel on Kaggle](https://www.kaggle.com/aleksandradeis/extending-pytorch-with-custom-activation-functions)
* [Activation functions wiki](https://en.wikipedia.org/wiki/Activation_function)
* [Tutorial](https://pytorch.org/docs/master/notes/extending.html) on PyTorch extending.
